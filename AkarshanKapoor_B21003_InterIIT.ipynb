{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using simpletransformers for training and testing our question and answer model.\n",
    "The transformers library was downloaded by the following command:\n",
    "%pip install simpletransformers --> needed for installing simple transformers on jupyter\n",
    "\n",
    "The above needs pre-installation of pytorch to be fully accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different frequently required libraries for data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for checking the metric for \"ANSWER_POSSIBLE\"\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the file. It is to be noted that only 60 percent of the entire data-set was used for faster model building and coherent checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file=pd.read_csv(\"/Users/akarshankapoor/Desktop/Development/ML:AI/train_data.csv\")\n",
    "train_file=train_file.drop(train_file.columns[0],axis=1)\n",
    "\n",
    "train_file=train_file[0:int(6*len(train_file)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Theme</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer_possible</th>\n",
       "      <th>Answer_text</th>\n",
       "      <th>Answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>True</td>\n",
       "      <td>['2003']</td>\n",
       "      <td>[526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What album made her a worldwide known artist?</td>\n",
       "      <td>True</td>\n",
       "      <td>['Dangerously in Love']</td>\n",
       "      <td>[505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Who managed the Destiny's Child group?</td>\n",
       "      <td>True</td>\n",
       "      <td>['Mathew Knowles']</td>\n",
       "      <td>[360]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyoncé rise to fame?</td>\n",
       "      <td>True</td>\n",
       "      <td>['late 1990s']</td>\n",
       "      <td>[276]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
       "      <td>True</td>\n",
       "      <td>['lead singer']</td>\n",
       "      <td>[290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45028</th>\n",
       "      <td>Galicia_(Spain)</td>\n",
       "      <td>The establishment of the Santa Hermandad in 14...</td>\n",
       "      <td>What percentage of Castille's total earnings w...</td>\n",
       "      <td>True</td>\n",
       "      <td>['10%']</td>\n",
       "      <td>[407]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45029</th>\n",
       "      <td>Galicia_(Spain)</td>\n",
       "      <td>The establishment of the Santa Hermandad in 14...</td>\n",
       "      <td>In spite of these wars, which exports did Gali...</td>\n",
       "      <td>True</td>\n",
       "      <td>['sardines, wood, and some cattle and wine']</td>\n",
       "      <td>[753]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45030</th>\n",
       "      <td>Galicia_(Spain)</td>\n",
       "      <td>After the rupture of the wars with Portugal an...</td>\n",
       "      <td>War broke out with which other countries?</td>\n",
       "      <td>True</td>\n",
       "      <td>['Portugal and Catalonia']</td>\n",
       "      <td>[35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45031</th>\n",
       "      <td>Galicia_(Spain)</td>\n",
       "      <td>After the rupture of the wars with Portugal an...</td>\n",
       "      <td>When did the Galician Junta more often stand u...</td>\n",
       "      <td>True</td>\n",
       "      <td>['second half of the 17th century']</td>\n",
       "      <td>[369]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45032</th>\n",
       "      <td>Galicia_(Spain)</td>\n",
       "      <td>After the rupture of the wars with Portugal an...</td>\n",
       "      <td>In what way was the tension between the monarc...</td>\n",
       "      <td>True</td>\n",
       "      <td>['there were frequent urban mutinies']</td>\n",
       "      <td>[578]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45033 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Theme                                          Paragraph  \\\n",
       "0              Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1              Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2              Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3              Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4              Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "...                ...                                                ...   \n",
       "45028  Galicia_(Spain)  The establishment of the Santa Hermandad in 14...   \n",
       "45029  Galicia_(Spain)  The establishment of the Santa Hermandad in 14...   \n",
       "45030  Galicia_(Spain)  After the rupture of the wars with Portugal an...   \n",
       "45031  Galicia_(Spain)  After the rupture of the wars with Portugal an...   \n",
       "45032  Galicia_(Spain)  After the rupture of the wars with Portugal an...   \n",
       "\n",
       "                                                Question  Answer_possible  \\\n",
       "0      When did Beyonce leave Destiny's Child and bec...             True   \n",
       "1          What album made her a worldwide known artist?             True   \n",
       "2                 Who managed the Destiny's Child group?             True   \n",
       "3                         When did Beyoncé rise to fame?             True   \n",
       "4         What role did Beyoncé have in Destiny's Child?             True   \n",
       "...                                                  ...              ...   \n",
       "45028  What percentage of Castille's total earnings w...             True   \n",
       "45029  In spite of these wars, which exports did Gali...             True   \n",
       "45030          War broke out with which other countries?             True   \n",
       "45031  When did the Galician Junta more often stand u...             True   \n",
       "45032  In what way was the tension between the monarc...             True   \n",
       "\n",
       "                                        Answer_text Answer_start  \n",
       "0                                          ['2003']        [526]  \n",
       "1                           ['Dangerously in Love']        [505]  \n",
       "2                                ['Mathew Knowles']        [360]  \n",
       "3                                    ['late 1990s']        [276]  \n",
       "4                                   ['lead singer']        [290]  \n",
       "...                                             ...          ...  \n",
       "45028                                       ['10%']        [407]  \n",
       "45029  ['sardines, wood, and some cattle and wine']        [753]  \n",
       "45030                    ['Portugal and Catalonia']         [35]  \n",
       "45031           ['second half of the 17th century']        [369]  \n",
       "45032        ['there were frequent urban mutinies']        [578]  \n",
       "\n",
       "[45033 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for any model that is created... it was divided into 2 parts... the train and the test part. \n",
    "The QuestionAnsweringModel within simple transoformers has aspects for training, testing and predicting. The prediction file was provided later. 70 percent of the extracted file was used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_len=len(train_file)\n",
    "train_test_ratio=0.7\n",
    "value_id=int(train_test_ratio*file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.DataFrame(train_file[:value_id])\n",
    "test=pd.DataFrame(train_file[value_id:]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided did not have the format specified for training the model, hence it was converted into a list of dictionaries according to the format specified.....\n",
    "This had to be done both with the train and test data......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding unique Paragraphs across the dataset:\n",
    "train_inst=train[\"Paragraph\"].unique()\n",
    "\n",
    "training_data=[]\n",
    "id=1\n",
    "#According to each paragraph context the questions were assigned unique IDs and were tokenized into \"is_impossible\" and \"answer_text\" format as required.\n",
    "for inst in train_inst:\n",
    "    dictionary={}\n",
    "    current=train.loc[train['Paragraph'] == inst]\n",
    "    current=current.reset_index(drop=True)\n",
    "    dictionary[\"context\"]=inst\n",
    "    dictionary[\"qas\"]=[]\n",
    "    for values in range(len(current)):\n",
    "        qas_dict={}\n",
    "        qas_dict[\"id\"]=str(id)\n",
    "        qas_dict[\"is_impossible\"]=~current[\"Answer_possible\"][values]\n",
    "        qas_dict[\"question\"]=current[\"Question\"][values]\n",
    "        qas_dict[\"answers\"]=[]\n",
    "        if(qas_dict[\"is_impossible\"]==False):\n",
    "            answer_dict={}\n",
    "            x=len(current[\"Answer_text\"][values])\n",
    "            y=len(current[\"Answer_start\"][values])\n",
    "            answer_dict[\"text\"]=current[\"Answer_text\"][values][2:x-2]\n",
    "            answer_dict[\"answer_start\"]=int(current[\"Answer_start\"][values][1:y-1])\n",
    "            qas_dict[\"answers\"].append(answer_dict)\n",
    "        id+=1\n",
    "        dictionary[\"qas\"].append(qas_dict) \n",
    "    training_data.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The same process as above was repeated again for the test data set.\n",
    "test_inst=test[\"Paragraph\"].unique()\n",
    "testing_data=[]\n",
    "id=1\n",
    "for inst in test_inst:\n",
    "    dictionary={}\n",
    "    current=test.loc[test['Paragraph'] == inst]\n",
    "    current=current.reset_index(drop=True)\n",
    "    dictionary[\"context\"]=inst\n",
    "    dictionary[\"qas\"]=[]\n",
    "    for values in range(len(current)):\n",
    "        qas_dict={}\n",
    "        qas_dict[\"id\"]=str(id)\n",
    "        qas_dict[\"is_impossible\"]=~current[\"Answer_possible\"][values]\n",
    "        qas_dict[\"question\"]=current[\"Question\"][values]\n",
    "        qas_dict[\"answers\"]=[]\n",
    "        if(qas_dict[\"is_impossible\"]==False):\n",
    "            answer_dict={}\n",
    "            x=len(current[\"Answer_text\"][values])\n",
    "            y=len(current[\"Answer_start\"][values])\n",
    "            answer_dict[\"text\"]=current[\"Answer_text\"][values][2:x-2]\n",
    "            answer_dict[\"answer_start\"]=int(current[\"Answer_start\"][values][1:y-1])\n",
    "            qas_dict[\"answers\"].append(answer_dict)\n",
    "        id+=1\n",
    "        dictionary[\"qas\"].append(qas_dict) \n",
    "    testing_data.append(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586\n",
      "6967\n"
     ]
    }
   ],
   "source": [
    "#The final length of test and train data set:\n",
    "print(len(testing_data))\n",
    "print(len(training_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the question answering model and the logging statistics for evaluating the train part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Configuring the model... the model parameters were specified as follows:\n",
    "model_devrev= QuestionAnsweringArgs()\n",
    "model_devrev.train_batch_size= 8\n",
    "model_devrev.evaluate_during_training= False\n",
    "model_devrev.num_train_epochs=1\n",
    "model_devrev.reprocess_input_data= True\n",
    "model_devrev.n_best_size=5\n",
    "model_devrev.learning_rate=3e-5\n",
    "\n",
    "finmod= QuestionAnsweringModel(\"distilbert\",\"distilbert-base-cased\",args=model_devrev,use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "Could not find answer: '\"This Can't Be Life\",' vs. '\"This Can\\'t Be Life\"'\n",
      "Could not find answer: '\"Hey Mama\", as well as a cover of Journey's \"Don't Stop Believin'\", to' vs. '\"Hey Mama\", as well as a cover of Journey\\'s \"Don\\'t Stop Believin\\'\"'\n",
      "Could not find answer: 'John Lennon's \"Imagine\"' vs. 'John Lennon\\'s \"Imagine\"'\n",
      "Could not find answer: '6'2\"' vs. '6\\'2\"'\n",
      "Could not find answer: '5'10\"' vs. '5\\'10\"'\n",
      "Could not find answer: '\"What Obama Isn't: Black Like Me.\"' vs. '\"What Obama Isn\\'t: Black Like Me.\"'\n",
      "Could not find answer: '\"It's House\"' vs. '\"It\\'s House\"'\n",
      "Could not find answer: 'Steve \"Silk\" Hurley's \"Jack Your Body\"' vs. 'Steve \"Silk\" Hurley\\'s \"Jack Your Body\"'\n",
      "Could not find answer: '\"Baseball's Sad Lexicon,\"' vs. '\"Baseball\\'s Sad Lexicon,'\n",
      "Could not find answer: '\"which attempts to capture information such as 'what', 'when' and 'where'\". With' vs. '\"which attempts to capture information such as \\'what\\', \\'when\\' and \\'where\\''\n",
      "Could not find answer: '\"The Queen's House\".' vs. '\"The Queen\\'s House\"'\n",
      "convert squad examples to features: 100%|██████████| 31523/31523 [00:26<00:00, 1182.99it/s]\n",
      "add example index and unique id: 100%|██████████| 31523/31523 [00:00<00:00, 1101505.79it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5cadbcb90b4c77a54ece41c786ea2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e4eec91b54d46a550df476acccc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/3971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Training of distilbert model complete. Saved to outputs/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3971, 1.6060433517067356)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The model was then trained on the training data_set after configuring into the required format\n",
    "finmod.train_model(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 13510/13510 [00:12<00:00, 1119.69it/s]\n",
      "add example index and unique id: 100%|██████████| 13510/13510 [00:00<00:00, 1166763.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f5efd9f0f240e2bcf84017533d9456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/1712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The model was locally saved into the outputs directory and and was loaded for the testing part.\n",
    "finmod=QuestionAnsweringModel(\"distilbert\",\"outputs/\",use_cuda=False)\n",
    "\n",
    "#The remaining 30 percent of the data was tested upon to check if the model had been trained properly.\n",
    "result,text=finmod.eval_model(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': 5758, 'similar': 6946, 'incorrect': 806, 'eval_loss': -6.927762973531384}\n"
     ]
    }
   ],
   "source": [
    "#The results are obtained below.....the model performed reasonably well with very less incorrect reports\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction file was provided later. To make the the model ready for prediction on the provided file...a sample was tested out .... to confirm the accuracy of the model and check the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = [\n",
    "    {\n",
    "        \"context\": \"Peter Parker is Spiderman\",\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"question\": \"Who is Spiderman?\",\n",
    "                \"id\": \"0\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 577.33it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 19328.59it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7f3f61f4574c51b8382bfee74b9681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers, probabilities = finmod.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '0', 'answer': ['Peter Parker', '', 'Parker', 'Peter']}]\n",
      "[{'id': '0', 'probability': [0.960883934404576, 0.032658683934185036, 0.003435587910957817, 0.0017487183959488306]}]\n"
     ]
    }
   ],
   "source": [
    "#The answer for the above question can be seen below.\n",
    "print(answers)\n",
    "print(probabilities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final test file was loaded into model. This file again had to be made into the required format for prediction.\n",
    "This was done again by creating a list of dictionaries regarding the \"Paragraphs\" and their \"Questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_testfile=pd.read_csv(\"/Users/akarshankapoor/Desktop/Development/ML:AI/test_data/answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inst=final_testfile[\"context\"].unique()\n",
    "finaltesting_data=[]\n",
    "id=1\n",
    "for inst in test_inst:\n",
    "    dictionary={}\n",
    "    current=final_testfile.loc[final_testfile['context'] == inst]\n",
    "    current=current.reset_index(drop=True)\n",
    "    dictionary[\"context\"]=inst\n",
    "    dictionary[\"qas\"]=[]\n",
    "    for values in range(len(current)):\n",
    "        qas_dict={}\n",
    "        qas_dict[\"id\"]=str(id)\n",
    "        qas_dict[\"question\"]=current[\"question\"][values]\n",
    "        id+=1\n",
    "        dictionary[\"qas\"].append(qas_dict) \n",
    "    finaltesting_data.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.question_answering.question_answering_model: Converting to features started.\n",
      "convert squad examples to features: 100%|██████████| 66/66 [00:00<00:00, 206.83it/s]\n",
      "add example index and unique id: 100%|██████████| 66/66 [00:00<00:00, 478107.19it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6189678c174c7eaa0b702981bec409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer,prob=finmod.predict(finaltesting_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answers returned by finmod were in a different format than required for checking the accuracy so they were converted in to the required format so they were converted into the required dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "result_dict={}\n",
    "for vals in range(len(answer)):\n",
    "    if(answer[vals][\"answer\"][0]!=\"\"):\n",
    "       result_dict[\"answer_possible\"]=True\n",
    "       result_dict[\"answer\"]=answer[vals][\"answer\"][0]\n",
    "    else:\n",
    "        result_dict[\"answer_possible\"]=False\n",
    "        result_dict[\"answer\"]=\"[]\"\n",
    "    result.append(result_dict)\n",
    "    result_dict={}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_possible</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Felicitas Hayek (née von Juraschek). Friedrich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>vary but most hatch from eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Tucson Kitchen Musicians Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>first Saturday and Sunday of May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>True</td>\n",
       "      <td>Akira Toriyama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>True</td>\n",
       "      <td>Toei Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>True</td>\n",
       "      <td>Gohan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    answer_possible                                          answer\n",
       "0              True  Felicitas Hayek (née von Juraschek). Friedrich\n",
       "1              True                   vary but most hatch from eggs\n",
       "2              True            Tucson Kitchen Musicians Association\n",
       "3             False                                              []\n",
       "4              True                first Saturday and Sunday of May\n",
       "..              ...                                             ...\n",
       "61             True                                  Akira Toriyama\n",
       "62             True                                  Toei Animation\n",
       "63            False                                              []\n",
       "64             True                                           Gohan\n",
       "65            False                                              []\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The result of the answers Dataframe achieved from the finmod model.\n",
    "result=pd.DataFrame(result)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score is printed below: \n",
    "The accuracy achieved was significantly higher than expectation due to the no. of epoch being less and also use of lesser amount of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6212121212121212\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(final_testfile[\"answer_possible\"],result[\"answer_possible\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more challenging part of the probelem statement required that that the question had to be answered from a given set of paragraphs, i.e we had to check whether the question could be answered from any of the given set of paragraphs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive way to solve the above will be to simply predict for each question given a particular context. This method has been implemented below...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs=pd.read_csv(\"/Users/akarshankapoor/Desktop/Development/ML:AI/test_data/paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=pd.read_csv(\"/Users/akarshankapoor/Desktop/Development/ML:AI/test_data/questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for question in questions[\"question\"]:\n",
    "    final_question=\"\"\n",
    "    final_context=\"\"\n",
    "    final_answer=\"\"\n",
    "    is_possible=\"\"\n",
    "    for context in paragraphs[\"context\"]:\n",
    "        to_predict[0][\"context\"]=context\n",
    "        to_predict[0][\"qas\"][0][\"question\"]=question\n",
    "        answers, probabilities = finmod.predict(to_predict)\n",
    "        if(answers[0][\"answer\"][0]!=\"\" and probabilities[0][\"probability\"][0] > 0.5):\n",
    "            final_question=question\n",
    "            final_context=context\n",
    "            final_answer=answers[0][\"answer\"][0]\n",
    "            is_possible=\"True\"\n",
    "            break\n",
    "        else:\n",
    "            final_question=question\n",
    "            final_context=\"[]\"\n",
    "            final_answer=\"[]\"\n",
    "            is_possible=\"False\"\n",
    "    prediction.append([final_question,final_context,final_answer,is_possible])\n",
    "    print(\"Question done\")\n",
    "    print(final_question)\n",
    "    print(final_answer)\n",
    "    print(final_context)\n",
    "    print(is_possible)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method had to be stopped early due to less available time.\n",
    "\n",
    "However it can be improvised upon by using a \"Keyword Tokenizer\" inside the same simple transformers library. This method will identify the key term on which the paragraph is based upon and will then iterate through each of the provided questions thus reducing the amount of computation time.\n",
    "\n",
    "The above could be implemented in some further additional time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
